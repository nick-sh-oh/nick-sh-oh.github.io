<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> From Foundation to Foundational - Rethinking AI Model Development | Nick Oh </title> <meta name="author" content="Nick Oh"> <meta name="description" content="An examination of AI development that advocates for moving beyond mere scaling to embrace theoretical understanding"> <meta name="keywords" content="social science, artificial intelligence, nlp, interpretable ai"> <meta property="og:site_name" content="Nick Oh"> <meta property="og:type" content="article"> <meta property="og:title" content="Nick Oh | From Foundation to Foundational - Rethinking AI Model Development"> <meta property="og:url" content="https://nick-sh-oh.github.io/blog/2025/FoundationalAI/"> <meta property="og:description" content="An examination of AI development that advocates for moving beyond mere scaling to embrace theoretical understanding"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="From Foundation to Foundational - Rethinking AI Model Development"> <meta name="twitter:description" content="An examination of AI development that advocates for moving beyond mere scaling to embrace theoretical understanding"> <meta name="twitter:site" content="@nickshoh"> <meta name="twitter:creator" content="@nickshoh"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/socius_logo.png?8319d022bee112628d445092cf7f37d3"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nick-sh-oh.github.io/blog/2025/FoundationalAI/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Nick </span> Oh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">From Foundation to Foundational - Rethinking AI Model Development</h1> <p class="post-meta"> January 22, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/socius"> <i class="fa-solid fa-hashtag fa-sm"></i> socius</a>   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>     ·   <a href="/blog/category/article"> <i class="fa-solid fa-tag fa-sm"></i> article</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Recent years have witnessed an arms race in artificial intelligence development, with each new model boasting more parameters, larger datasets, and broader capabilities than its predecessors. When <a href="https://hai.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford’s Institute for Human-Centered Artificial Intelligence</a> coined the term <a href="https://arxiv.org/abs/2108.07258" rel="external nofollow noopener" target="_blank">“foundation model”</a> in 2021, they captured something essential about this approach: <strong>the belief that sufficiently large models, trained on sufficiently large data, could serve as a foundation for almost any downstream task</strong>.</p> <p>Yet amidst this rush towards scale, we seem to have forgotten something. The difference between a <em>foundation</em> and something truly <em>foundational</em>.</p> <p>A foundation model, by Stanford’s definition, is any model that is trained on broad data (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks. It’s a perfectly serviceable definition, yet it speaks volumes about our current priorities in AI development. We’ve become rather enamoured with what these models can do, whilst paying considerably less attention to how or why they do it.</p> <p>What I propose instead is the development of what I call <strong>foundational models</strong> - AI systems developed with robust theoretical principles and foundations, accompanied by understanding of both their mechanistic underpinnings and emergent properties.</p> <h2 id="beyond-scale-the-case-for-theoretical-rigour-in-ai">Beyond Scale: The Case for Theoretical Rigour in AI</h2> <p>Consider the difference between building a tower and understanding architecture. One can stack bricks higher and higher, achieving impressive heights through sheer scale. But architecture - thoughtful, purposeful architecture - requires understanding of principles such as load-bearing structures, material properties, and aesthetic harmony. Similarly, while foundation models achieve remarkable results through scale and engineering, foundational models would emerge from a deeper wellspring fed by theoretical understanding, systematic investigation of their inner workings, and rigorous validation of their behaviours in the real world.</p> <div class="row mt-3"> <div class="col-12"> <div style="font-family: 'Courier New', monospace; padding: 0; background-color: #000033;"> <div style="border-top: 2px solid #FFB400; border-bottom: 2px solid #FFB400; padding: 10px 0; margin-bottom: 15px; text-align: center;"> <h5 style="color: #FFB400; margin: 0;"> ◄◄ SCALE VS UNDERSTANDING ►►<br> <small>Two Paths in AI Architecture</small> </h5> </div> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/foundational_ai/two_paths_in_ai-480.webp 480w,/assets/img/blog/foundational_ai/two_paths_in_ai-800.webp 800w,/assets/img/blog/foundational_ai/two_paths_in_ai-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blog/foundational_ai/two_paths_in_ai.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <details class="mb-3"> <summary style="color: #FFB400; cursor: pointer; padding: 10px; border-top: 1px solid #FFB400;"> Technical Details </summary> <div style="padding: 20px;"> <pre style="color: orange; margin: 0;"><code>{

  "architectural_metaphor": {
    "scale_driven": {
      "type": "<span style="color: #99FF99;">vertical_scaling</span>",
      "characteristics": [
        "<span style="color: #99FF99;">magnitude</span>",
        "<span style="color: #99FF99;">engineering</span>"
      ]
    },
    "principle_driven": {
      "type": "<span style="color: #99FF99;">theoretical_design</span>",
      "principles": [
        "<span style="color: #99FF99;">foundations</span>",
        "<span style="color: #99FF99;">principles</span>"
      ]
    }
  }
}</code></pre> <div style="border-top: 1px solid #FFB400; margin-top: 15px; padding-top: 15px; color: #FFB400;"> RENDERING: The juxtaposition illustrates two distinct approaches to AI development: the left structure represents scale-driven advancement through computational magnitude, whilst the right edifice exemplifies principle-driven progress through theoretical understanding. The contrast emphasises how architectural wisdom parallels AI development - one path relies on magnitude, the other on mathematical foundations and structural elegance. </div> </div> </details> </div> </div> </div> <p>This distinction becomes particularly relevant when we examine the current trajectory of AI development. Leading researchers like <a href="https://www.youtube.com/watch?v=9uw3F6rndnA" rel="external nofollow noopener" target="_blank">Andrej Karpathy note that the current zeitgeist is keeping the transformer, making the models bigger</a>, while <a href="https://www.youtube.com/watch?v=n4IQOBka8bc" rel="external nofollow noopener" target="_blank">Geoffrey Hinton recalls how Ilya Sutskever recognised early on that scaling would be a crucial factor in AI progress</a>. While scaling has indeed proven to be a powerful driver of progress, it represents just one dimension of advancement. I contend that other critical factors - like architecture design, training/inferencing dynamics, and theoretical understanding - must play equally important roles in building intelligent systems.</p> <p>The scale-focused approach might seem intuitive. Larger models with more computation consistently demonstrate superior capabilities. As Sutton compellingly argues in his <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" rel="external nofollow noopener" target="_blank">‘Bitter Lesson’</a>, ‘general methods that leverage computation are ultimately the most effective, and by a large margin’. While this bitter lesson rightly warns against encoding human domain knowledge into AI systems, it doesn’t preclude the need for understanding how these systems learn and process information.</p> <p>The key point that I would like to emphasise here is that scaling (foundation models) and understanding (foundational models) serve different but complementary purposes: scaling demonstrates what’s possible through computation, while understanding enables us to harness and orchestrate these capabilities effectively. This becomes particularly vital as AI systems become more deeply integrated into our lives, where both performance and reliability are essential.</p> <h2 id="the-path-forward">The Path Forward?</h2> <p>I must re-emphasise that the foundational model approach represents not an opposition to foundation models, but a synthesis of engineering achievement and theoretical understanding. When we observe phenomena like model <a href="https://arxiv.org/abs/2201.02177" rel="external nofollow noopener" target="_blank">grokking</a>, we see both the power of scaled computation and the need for theoretical frameworks to explain sudden comprehension breakthroughs. Mechanistic interpretability has begun to bridge this gap, offering tools for understanding neural networks, while recent editorial <a href="https://www.nature.com/articles/s42256-023-00703-8" rel="external nofollow noopener" target="_blank">linking language models with linguistic theories</a> suggests new ways to examine and question our understanding of AI capabilities. My research vision isn’t to replace foundation models, but to understand them systematically, enabling us to build better systems through insight rather than scale alone - transforming our understanding from knowing <em>what</em> works to knowing <em>why</em> it works.</p> <p>This shift from foundation to foundational models represents more than a technical evolution - it embodies a philosophical reimagining of artificial intelligence as profound as the transition from alchemy to chemistry, marking the progression from a practice based primarily on empirical experimentation to one grounded in systematic understanding. Just as chemical theory allowed us to predict and explain reactions rather than merely observe them, robust foundations will enable us to predict and explain AI behaviours, moving us beyond mere observation and replication towards true mastery.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/PersonalJourney/">From Markets to Minds - My Personal Journey as a Researcher</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/AIrevolution/">The AI Revolution - Augmentation, Not Replacement</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Migrate2Substack/">Off to Substack!</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Nick Oh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>