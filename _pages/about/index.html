<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Hi there! I’m Nick (Seungheon) Oh – a researcher experimenting at the intersection between every field that ever studied “thinking” and every machine that’s trying to “think”.</p> <p>Basically I’m interested in two experiments: whether sciences that explained humans can improve machines (not just performance, but how they collaborate with us); and whether machines can test human theories at impossible scales.</p> <p>After studying Politics and Economics at <a href="https://www.lse.ac.uk/" rel="external nofollow noopener" target="_blank">LSE</a>, I worked as a Junior NLP Engineer at <a href="https://numencapital.com/" rel="external nofollow noopener" target="_blank">Numen Capital</a> while sketching out <a href="https://www.socialscience.ai" rel="external nofollow noopener" target="_blank">socialscience.ai</a> – a project to bring AI tools to social scientists. But building it revealed the more interesting question was the reverse: instead of AI serving social science, what if the disciplines that studied humans could advance machine intelligence? That flip became <a href="https://socius.org" rel="external nofollow noopener" target="_blank">socius labs</a>, now an independent research lab supported by LSE and LSE Generate exploring this convergence.</p> <p>Current ongoing research spans metacognitive architectures for machines (Monitor-Generate-Verify, System 1.5, Before you 〈think〉, monitor), philosophical arguments on why AI’s imperfect explanations can still advance knowledge (In Defence of Post-hoc Explainability) and research infrastructures (PETLP, sentibank, RedditHarbor). Increasingly, I’m fascinated by whether machines have subjective “feelings” we can measure, and how AI agent societies might become laboratories where we test different theories.</p> </body></html>