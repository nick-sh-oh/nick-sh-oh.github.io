---
layout: about
title: about
permalink: /
subtitle: Researcher @ <a href="https://www.socius.org/">socius labs</a>

profile:
  align: right
  image: profile_picture_b2c.jpg
  image_circular: false # crops the image to make it circular
  more_info: false

news: false # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi there! I’m Nick (Seungheon) Oh -- a researcher experimenting at the intersection between every field that ever studied “thinking” and every machine that's trying to “think”. 

Basically I'm interested in two experiments: whether fields that explained humans can improve machines (not just performance, but how they collaborate with us); and whether machines can test human theories at impossible scales. 

After studying Politics and Economics at [LSE](https://www.lse.ac.uk/), I worked as a Junior NLP Engineer at a London based hedge fund while sketching out [socialscience.ai](https://www.socialscience.ai) -- a side project to bring ML models to social scientists. But building it revealed the more interesting question was the reverse. Instead of AI/ML serving social science, what if the disciplines that studied humans could advance machine intelligence? That flip became [socius labs](https://socius.org), now an independent research lab supported by LSE and LSE Generate exploring this convergence.

I am currently informally advised by [Professor Fernand Gobet](https://scholar.google.com/citations?user=jeJqwKsAAAAJ), collaborating on bridging cognitive science and machine intelligence.

Current research explores whether metacognitive monitoring is a fundamental functional requirement for intelligence, and whether XAI can generate epistemically legitimate knowledge despite its imperfect fidelity. Increasingly, I'm drawn to using neural networks of varying scales and architectures — from RNNs to LLMs — as cognitive models to better understand the computational principles underlying humans. I’m also interested in whether we can measure and operationalise metacognitive functions and subjective "feelings" in machines. 