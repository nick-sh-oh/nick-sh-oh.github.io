<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nick-sh-oh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nick-sh-oh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-06T05:38:24+00:00</updated><id>https://nick-sh-oh.github.io/feed.xml</id><title type="html">blank</title><subtitle>Portfolio </subtitle><entry><title type="html">Off to Substack!</title><link href="https://nick-sh-oh.github.io/blog/2025/Migrate2Substack/" rel="alternate" type="text/html" title="Off to Substack!"/><published>2025-05-02T00:00:00+00:00</published><updated>2025-05-02T00:00:00+00:00</updated><id>https://nick-sh-oh.github.io/blog/2025/Migrate2Substack</id><content type="html" xml:base="https://nick-sh-oh.github.io/blog/2025/Migrate2Substack/"><![CDATA[<p>I’ve decided to move my scribbles, sketches, and semi-coherent thoughts over to Substack. It’s a bit cosier there, and frankly, a better place for the sort of things I like to write (and you hopefully like to read).</p> <p>All future posts will live here: <a href="https://rawlog.substack.com/">Substack link</a> — come say hi, and subscribe if you’re keen.</p> <div class="row mt-3"> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/substack/substack_observatory-480.webp 480w,/assets/img/blog/substack/substack_observatory-800.webp 800w,/assets/img/blog/substack/substack_observatory-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/substack/substack_observatory.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="article"/><category term="socius"/><summary type="html"><![CDATA[Packing up my digital thoughts and moving house — come find me on Substack]]></summary></entry><entry><title type="html">From Foundation to Foundational - Rethinking AI Model Development</title><link href="https://nick-sh-oh.github.io/blog/2025/FoundationalAI/" rel="alternate" type="text/html" title="From Foundation to Foundational - Rethinking AI Model Development"/><published>2025-01-22T00:00:00+00:00</published><updated>2025-01-22T00:00:00+00:00</updated><id>https://nick-sh-oh.github.io/blog/2025/FoundationalAI</id><content type="html" xml:base="https://nick-sh-oh.github.io/blog/2025/FoundationalAI/"><![CDATA[<p>Recent years have witnessed an arms race in artificial intelligence development, with each new model boasting more parameters, larger datasets, and broader capabilities than its predecessors. When <a href="https://hai.stanford.edu/">Stanford’s Institute for Human-Centered Artificial Intelligence</a> coined the term <a href="https://arxiv.org/abs/2108.07258">“foundation model”</a> in 2021, they captured something essential about this approach: <strong>the belief that sufficiently large models, trained on sufficiently large data, could serve as a foundation for almost any downstream task</strong>.</p> <p>Yet amidst this rush towards scale, we seem to have forgotten something. The difference between a <em>foundation</em> and something truly <em>foundational</em>.</p> <p>A foundation model, by Stanford’s definition, is any model that is trained on broad data (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks. It’s a perfectly serviceable definition, yet it speaks volumes about our current priorities in AI development. We’ve become rather enamoured with what these models can do, whilst paying considerably less attention to how or why they do it.</p> <p>What I propose instead is the development of what I call <strong>foundational models</strong> - AI systems developed with robust theoretical principles and foundations, accompanied by understanding of both their mechanistic underpinnings and emergent properties.</p> <h2 id="beyond-scale-the-case-for-theoretical-rigour-in-ai">Beyond Scale: The Case for Theoretical Rigour in AI</h2> <p>Consider the difference between building a tower and understanding architecture. One can stack bricks higher and higher, achieving impressive heights through sheer scale. But architecture - thoughtful, purposeful architecture - requires understanding of principles such as load-bearing structures, material properties, and aesthetic harmony. Similarly, while foundation models achieve remarkable results through scale and engineering, foundational models would emerge from a deeper wellspring fed by theoretical understanding, systematic investigation of their inner workings, and rigorous validation of their behaviours in the real world.</p> <div class="row mt-3"> <div class="col-12"> <div style="font-family: 'Courier New', monospace; padding: 0; background-color: #000033;"> <div style="border-top: 2px solid #FFB400; border-bottom: 2px solid #FFB400; padding: 10px 0; margin-bottom: 15px; text-align: center;"> <h5 style="color: #FFB400; margin: 0;"> ◄◄ SCALE VS UNDERSTANDING ►►<br/> <small>Two Paths in AI Architecture</small> </h5> </div> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/foundational_ai/two_paths_in_ai-480.webp 480w,/assets/img/blog/foundational_ai/two_paths_in_ai-800.webp 800w,/assets/img/blog/foundational_ai/two_paths_in_ai-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/foundational_ai/two_paths_in_ai.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <details class="mb-3"> <summary style="color: #FFB400; cursor: pointer; padding: 10px; border-top: 1px solid #FFB400;"> Technical Details </summary> <div style="padding: 20px;"> <pre style="color: orange; margin: 0;"><code>{

  "architectural_metaphor": {
    "scale_driven": {
      "type": "<span style="color: #99FF99;">vertical_scaling</span>",
      "characteristics": [
        "<span style="color: #99FF99;">magnitude</span>",
        "<span style="color: #99FF99;">engineering</span>"
      ]
    },
    "principle_driven": {
      "type": "<span style="color: #99FF99;">theoretical_design</span>",
      "principles": [
        "<span style="color: #99FF99;">foundations</span>",
        "<span style="color: #99FF99;">principles</span>"
      ]
    }
  }
}</code></pre> <div style="border-top: 1px solid #FFB400; margin-top: 15px; padding-top: 15px; color: #FFB400;"> RENDERING: The juxtaposition illustrates two distinct approaches to AI development: the left structure represents scale-driven advancement through computational magnitude, whilst the right edifice exemplifies principle-driven progress through theoretical understanding. The contrast emphasises how architectural wisdom parallels AI development - one path relies on magnitude, the other on mathematical foundations and structural elegance. </div> </div> </details> </div> </div> </div> <p>This distinction becomes particularly relevant when we examine the current trajectory of AI development. Leading researchers like <a href="https://www.youtube.com/watch?v=9uw3F6rndnA">Andrej Karpathy note that the current zeitgeist is keeping the transformer, making the models bigger</a>, while <a href="https://www.youtube.com/watch?v=n4IQOBka8bc">Geoffrey Hinton recalls how Ilya Sutskever recognised early on that scaling would be a crucial factor in AI progress</a>. While scaling has indeed proven to be a powerful driver of progress, it represents just one dimension of advancement. I contend that other critical factors - like architecture design, training/inferencing dynamics, and theoretical understanding - must play equally important roles in building intelligent systems.</p> <p>The scale-focused approach might seem intuitive. Larger models with more computation consistently demonstrate superior capabilities. As Sutton compellingly argues in his <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">‘Bitter Lesson’</a>, ‘general methods that leverage computation are ultimately the most effective, and by a large margin’. While this bitter lesson rightly warns against encoding human domain knowledge into AI systems, it doesn’t preclude the need for understanding how these systems learn and process information.</p> <p>The key point that I would like to emphasise here is that scaling (foundation models) and understanding (foundational models) serve different but complementary purposes: scaling demonstrates what’s possible through computation, while understanding enables us to harness and orchestrate these capabilities effectively. This becomes particularly vital as AI systems become more deeply integrated into our lives, where both performance and reliability are essential.</p> <h2 id="the-path-forward">The Path Forward?</h2> <p>I must re-emphasise that the foundational model approach represents not an opposition to foundation models, but a synthesis of engineering achievement and theoretical understanding. When we observe phenomena like model <a href="https://arxiv.org/abs/2201.02177">grokking</a>, we see both the power of scaled computation and the need for theoretical frameworks to explain sudden comprehension breakthroughs. Mechanistic interpretability has begun to bridge this gap, offering tools for understanding neural networks, while recent editorial <a href="https://www.nature.com/articles/s42256-023-00703-8">linking language models with linguistic theories</a> suggests new ways to examine and question our understanding of AI capabilities. My research vision isn’t to replace foundation models, but to understand them systematically, enabling us to build better systems through insight rather than scale alone - transforming our understanding from knowing <em>what</em> works to knowing <em>why</em> it works.</p> <p>This shift from foundation to foundational models represents more than a technical evolution - it embodies a philosophical reimagining of artificial intelligence as profound as the transition from alchemy to chemistry, marking the progression from a practice based primarily on empirical experimentation to one grounded in systematic understanding. Just as chemical theory allowed us to predict and explain reactions rather than merely observe them, robust foundations will enable us to predict and explain AI behaviours, moving us beyond mere observation and replication towards true mastery.</p>]]></content><author><name></name></author><category term="article"/><category term="socius"/><category term="AI"/><summary type="html"><![CDATA[An examination of AI development that advocates for moving beyond mere scaling to embrace theoretical understanding]]></summary></entry><entry><title type="html">From Markets to Minds - My Personal Journey as a Researcher</title><link href="https://nick-sh-oh.github.io/blog/2024/PersonalJourney/" rel="alternate" type="text/html" title="From Markets to Minds - My Personal Journey as a Researcher"/><published>2024-12-03T00:00:00+00:00</published><updated>2024-12-03T00:00:00+00:00</updated><id>https://nick-sh-oh.github.io/blog/2024/PersonalJourney</id><content type="html" xml:base="https://nick-sh-oh.github.io/blog/2024/PersonalJourney/"><![CDATA[<p>I’m a researcher with an unconventional background - a BSc in Politics and Economics who now focus on researching AI systems. Here’s my personal journey as a researcher, with its unexpected turns and discoveries that shaped my approach to artificial intelligence.</p> <p>Around 2020 I was nestled in a quiet corner on the second floor of the LSE library, surrounded by papers about the 2008 financial crisis. <a href="https://en.wikipedia.org/wiki/Cheryl_Schonhardt-Bailey">Prof. Schonhardt-Bailey</a>’s GV309 course, <em>Politics of Money and Finance in Comparative Perspective</em>, had led me down a fascinating rabbit hole. Until then, most of my Economics courses had been a parade of numbers, graphs, and equations. But GV309 revealed a different story – institutions, ideas, and human interests shaping financial decisions. That contrast sparked something in me. The same market event could look entirely different depending on whether you focused on the mathematical models or the human elements driving them. (In hindsight, perhaps I should have enrolled in behavioural economics - it might have shown me this duality sooner.)</p> <div class="row mt-3"> <div class="col-12"> <div style="font-family: 'Courier New', monospace; padding: 0; background-color: #000033;"> <div style="border-top: 2px solid #FFB400; border-bottom: 2px solid #FFB400; padding: 10px 0; margin-bottom: 15px; text-align: center;"> <h5 style="color: #FFB400; margin: 0;"> ◄◄ MARKET DUALITY ►►<br/> <small>A Tale of Numbers and Human Nature</small> </h5> </div> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/personal_journey/market_event-480.webp 480w,/assets/img/blog/personal_journey/market_event-800.webp 800w,/assets/img/blog/personal_journey/market_event-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/personal_journey/market_event.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <details class="mb-3"> <summary style="color: #FFB400; cursor: pointer; padding: 10px; border-top: 1px solid #FFB400;"> caption </summary> <div style="padding: 20px;"> <pre style="color: orange; margin: 0;"><code>{

  "market_model": {
    "left_hemisphere": {
      "type": "<span style="color: #99FF99;">quantitative analytics</span>",
      "components": [
        "<span style="color: #99FF99;">modeling</span>",
        "<span style="color: #99FF99;">graphs</span>",
        "<span style="color: #99FF99;">equations</span>"
      ]
    },
    "right_hemisphere": {
      "type": "<span style="color: #99FF99;">human behaviour</span>",
      "components": [
        "<span style="color: #99FF99;">ideologies</span>",
        "<span style="color: #99FF99;">interests</span>",
        "<span style="color: #99FF99;">institutions</span>"
      ]
    },
    "central_display": "<span style="color: #99FF99;">integrated market visualisation</span>"
  }
}</code></pre> <div style="border-top: 1px solid #FFB400; margin-top: 15px; padding-top: 15px; color: #FFB400;"> RENDERING: The split-screen visualisation presents a market event through complementary lenses - mathematical models and formulae on the left, institutional and human factors on the right. At the center lies the marketplace itself, bustling with activity, where these two realms of understanding converge to shape market outcomes. This duality represents how markets emerge from the interplay between quantitative precision and human behaviour. </div> </div> </details> </div> </div> </div> <p>After graduating from LSE, I was offered a role as a Junior NLP Engineer at <a href="https://numencapital.com/">Numen Capital</a> - a stroke of fortune and timing for someone without a Computer Science degree. Working on the Knowsis research team, I was building NLP pipelines and transformer-based classifiers to analyse market sentiment on ESG. While our classifier boasted an impressive 97% accuracy, what truly fascinated me was a more fundamental question: why did we need sentiment analysis at all? If markets were purely rational, why would sentiment matter? Yet there I was, developing rule-based sentiment analysers and domain-specific dictionaries because market movements weren’t just about numbers – they were about human psychology, emotions, and sometimes deeply irrational behaviour. This curiosity about the foundational elements behind market movements would later become one of the founding principles of <a href="https://socius.org/">socius</a>.</p> <p>During my time at Numen, I began noticing something curious about how we study sentiment in text. Everyone was rushing to build bigger, more complex models, but they were missing something fundamental: What exactly is sentiment? How do we humans understand and process emotions in the first place? This wasn’t just academic curiosity anymore - it was becoming clear that if we’re going to build AI systems that understand human emotions, we should first understand how we ourselves process them.</p> <h2 id="building-bridges-from-ŷ-to-b̂">Building Bridges: From <em>Ŷ</em> to <em>B̂</em></h2> <p>This tension between understanding and performance was everywhere in AI development. A % gain in accuracy was celebrated more than building models from robust theories. Coming from a social science background, I was trained to prioritise understanding above all else. The essence was <em>B̂</em>: mechanism, mediation, and moderation - we weren’t satisfied just knowing that X affected Y; we wanted to unravel the <em>how</em> and <em>why</em>, to peek inside the black box of causation. Yet the core of deep learning seemed fixated on <em>Ŷ</em>: optimisation, regularisation, evaluation. As <a href="https://link.springer.com/article/10.1007/s00146-022-01540-w">Rahul, Verhagen and Kirk (2022)</a> put it, “social scientists have previously had a preoccupation with parsimonious explanation and inferential <em>B̂</em>, as opposed to predictive <em>Ŷ</em> questions”.</p> <p>I wanted to close this gap. I wanted to apply principles of social science to AI development. So I started my own lab - originally named rather straightforwardly as ‘socialscience.ai’, before becoming socius. In hindsight, this was such a bold move. Other than having quasi-lab experience in industry, I had neither a PhD in Computer Science nor proper academic lab experience. But looking back, it wasn’t that I was at the peak of confidence on the Dunning-Kruger curve - rather, it was more of an ignorant courage. I knew I wasn’t fully ready, but at the time, I felt that I needed and wanted to. So in October 2022, I took the first steps toward building socius.</p> <p>Of course, the first year was the most challenging. It was like doing a PhD with no supervision - teaching myself, guiding myself through the uncharted. I started by diving deep into how researchers had approached sentiment analysis over the years. What fascinated me was how different academic traditions had conceptualised and operationalised sentiment - each dictionary representing years of careful theoretical work and empirical validation. That’s how <a href="https://github.com/socius-org/sentibank">sentibank</a> was born - not just as another sentiment analysis tool, but as an encyclopedic hub bringing together these diverse approaches to understanding human emotion. While not strictly an AI system itself, sentibank represented something profound: an attempt to assist black-box AI models with theoretically-grounded lexicons. These weren’t just arbitrary scores; we understood their origins, their theoretical foundations, their why. In many ways, sentibank embodied what would become a core principle at socius: creating AI systems that think in more humanly understandable ways.</p> <h2 id="from-market-psychology-to-cognitive-science">From Market Psychology to Cognitive Science</h2> <p>During my time studying sentiment, the deeper I delved into human emotion and decision-making, the more I found myself drawn into cognitive science. I became fascinated by how experts make decisions – not the careful, analytical choices we often assume, but the quick, intuitive judgments that come from years of experience.</p> <p>I still remember the day I first read about System 1 and System 2 thinking. It was like finding a missing puzzle piece. The idea that human thinking isn’t just logical or emotional, but a complex dance between intuition and analysis – it explained so much about the questions I had been grappling with.</p> <div class="row mt-3"> <div class="col-12"> <div style="font-family: 'Courier New', monospace; padding: 0; background-color: #000033;"> <div style="border-top: 2px solid #FFB400; border-bottom: 2px solid #FFB400; padding: 10px 0; margin-bottom: 15px; text-align: center;"> <h5 style="color: #FFB400; margin: 0;"> ◄◄ THE TWO MINDS ►►<br/> <small>A Portrait of Dual Process Theory</small> </h5> </div> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/personal_journey/system1_2-480.webp 480w,/assets/img/blog/personal_journey/system1_2-800.webp 800w,/assets/img/blog/personal_journey/system1_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/personal_journey/system1_2.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <details class="mb-3"> <summary style="color: #FFB400; cursor: pointer; padding: 10px; border-top: 1px solid #FFB400;"> caption </summary> <div style="padding: 20px;"> <pre style="color: orange; margin: 0;"><code>{

  "cognitive_framework": {
    "processors": {
      "left_unit": "<span style="color: #99FF99;">System-1</span>",
      "right_unit": "<span style="color: #99FF99;">System-2</span>"
    },
    "theorists": "<span style="color: #99FF99;">Daniel Kahneman, Jonathan St B. T. Evans</span>"
  }
}</code></pre> <div style="border-top: 1px solid #FFB400; margin-top: 15px; padding-top: 15px; color: #FFB400;"> RENDERING: This portrait depicts the classical distinction between System 1 and System 2 thinking. The mathematical diagrams between the figures emphasise the relationship between intuitive and analytical processing, whilst the unified landscape suggests their operation within a single cognitive framework. </div> </div> </details> </div> </div> </div> <p>This led to my research collaboration with <a href="https://en.wikipedia.org/wiki/Fernand_Gobet">Prof. Fernand Gobet</a>. Working together on <a href="https://neurips.cc/virtual/2024/104306">System 1.5</a>, we examined how expert cognition could inform AI development. Just as social sciences seek to explain phenomena through multiple levels of analysis, we proposed a framework that mirrors how human experts navigate between intuitive and analytical thinking. This wasn’t just about building faster or more accurate systems - it was about creating AI that processes information in ways we can naturally understand and explain, reflecting personal philosophy that AI development must balance theory-driven approaches with multi-scale analysis.</p> <div class="row mt-3"> <div class="col-12"> <div style="font-family: 'Courier New', monospace; padding: 0; background-color: #000033;"> <div style="border-top: 2px solid #FFB400; border-bottom: 2px solid #FFB400; padding: 10px 0; margin-bottom: 15px; text-align: center;"> <h5 style="color: #FFB400; margin: 0;"> ◄◄ SYSTEM 1.5 ►►<br/> <small>The Dance of Intuition and Analysis</small> </h5> </div> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/personal_journey/system1_5-480.webp 480w,/assets/img/blog/personal_journey/system1_5-800.webp 800w,/assets/img/blog/personal_journey/system1_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/personal_journey/system1_5.jpg" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <details class="mb-3"> <summary style="color: #FFB400; cursor: pointer; padding: 10px; border-top: 1px solid #FFB400;"> caption </summary> <div style="padding: 20px;"> <pre style="color: orange; margin: 0;"><code>{

  "cognitive_interface": {
    "left_entity": {
      "type": "<span style="color: #99FF99;">System 1</span>",
      "attributes": "<span style="color: #99FF99;">rapid response core</span>",
      "signature": "<span style="color: #99FF99;">scarlet energetic stance</span>"
    },
    "mediator": {
      "type": "<span style="color: #99FF99;">System 1.5</span>",
      "function": "<span style="color: #99FF99;">metacognitive regulation</span>"
    },
    "right_entity": {
      "type": "<span style="color: #99FF99;">System 2</span>",
      "attributes": "<span style="color: #99FF99;">analytical processing unit</span>",
      "signature": "<span style="color: #99FF99;">azure contemplative stance</span>"
    }
  }
}</code></pre> <div style="border-top: 1px solid #FFB400; margin-top: 15px; padding-top: 15px; color: #FFB400;"> RENDERING: The spiral wave betwixt the figures represents System 1.5's dynamic role in mediating between intuitive System 1 (left, in scarlet) and analytical System 2 (right, in azure). The flowing element symbolises the continuous interplay between swift, instinctive thinking and deliberative reasoning. </div> </div> </details> </div> </div> </div> <p>The development of System 1.5 sparked an intriguing question: if human experts can provide valid explanations after making intuitive decisions, why do we demand complete mechanical transparency from AI systems? After all, experts across domains routinely make effective decisions while their subsequent explanations often involve post-hoc rationalisation rather than complete, factive accounts of their decision-making processes (e.g., see <a href="https://doi.org/10.1016/j.cogpsych.2007.02.001">Bilalić, McLeod and Gobet, 2008</a>). This insight led me to explore AI interpretability from a philosophical perspective. While many researchers insisted on building inherently transparent systems, I noticed an interesting parallel with human expertise: just as experts often construct valid explanations after making intuitive decisions, perhaps post-hoc interpretability in AI wasn’t a weakness, but rather a natural reflection of how understanding emerges from complex systems. This philosophical stance ultimately defends post-hoc explainability in AI systems, challenging the notion that complete mechanistic understanding is necessary for meaningful scientific insight.</p> <p>Looking back, I can see how each step of this journey was necessary. Understanding market emotions led to studying sentiment, which led to exploring human cognition, which in turn is helping us build more human-centered AI systems. Each piece connected to the next in ways I couldn’t have predicted but now seem almost inevitable.</p> <p>That undergraduate student in the LSE library, puzzling over market crashes and human behaviour, could never have predicted where this journey would lead. But that’s the beauty of research driven by genuine curiosity – it takes you places you never expected to go. The questions that drive me today have evolved from those early wonderings but maintain the same core focus on human understanding:</p> <ul> <li>How can we develop AI systems that learn and explain their knowledge more like humans do?</li> <li>How can we bridge the gap between mechanistic and holistic understanding in AI?</li> <li>What can cognitive science teach us about building AI systems that process information more naturally and effectively?</li> <li>How might we implement theory-driven AI development at scale while maintaining the human element?</li> </ul> <p>There’s a peculiar poetry in how life unfolds. What began as a puzzled undergraduate’s musings in the LSE library has bloomed into something I never could have sketched out in advance - rather like how the most fascinating AI behaviours emerge from seemingly simple principles. Each step of this journey, from market sentiment to machine cognition, has felt less like following a map and more like reading a compass: knowing roughly where North is, but discovering the actual terrain as you walk. Perhaps that’s the real gift of an unconventional path - it teaches you to see connections that others might miss, to find new ways through old problems.</p>]]></content><author><name></name></author><category term="article"/><category term="PersonalJourney"/><category term="socius"/><category term="Philosophy"/><summary type="html"><![CDATA[My personal journey from studying politics and economics to founding an AI research lab.]]></summary></entry><entry><title type="html">The AI Revolution - Augmentation, Not Replacement</title><link href="https://nick-sh-oh.github.io/blog/2024/AIrevolution/" rel="alternate" type="text/html" title="The AI Revolution - Augmentation, Not Replacement"/><published>2024-07-10T00:00:00+00:00</published><updated>2024-07-10T00:00:00+00:00</updated><id>https://nick-sh-oh.github.io/blog/2024/AIrevolution</id><content type="html" xml:base="https://nick-sh-oh.github.io/blog/2024/AIrevolution/"><![CDATA[<div class="row mt-3"> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/ai_revolution/aztec-480.webp 480w,/assets/img/blog/ai_revolution/aztec-800.webp 800w,/assets/img/blog/ai_revolution/aztec-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/ai_revolution/aztec.png" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In the early 1500s, a handful of Spanish conquistadors toppled vast empires in the Americas: Cortes and about 500 Spaniards conquered the Aztec empire of several million; Pizarro and ~300 Spaniards conquered the Inca empire of several million. Their success wasn’t due to god-like power, but rather through technological superiority. Today, we stand at the precipice of a similar paradigm shift – not through conquest, but through artificial intelligence.</p> <p>Recent weeks, I’ve noticed a dialogue surrounding Leopold Aschenbrenner’s Situational Awareness. While much focus has been on national security implications, I’d like to explore a more immediate concern: how AI is reshaping our workforce.</p> <h2 id="the-ai-advantage">The AI Advantage</h2> <p><a href="https://ourworldindata.org/artificial-intelligence">Our World in Data shows AI systems surpassing human performance in various domains at an exponential rate</a>. This isn’t just about machines beating us at chess; it’s about redefining the very nature of work and human potential. However, Generative AI’s actual impact on the market remains under-documented. It’s unclear whether the perceived anxiety in the media reflects real productivity losses or gains. To truly understand this shift, we must look beyond media anxiety to frontline industry insights.</p> <div class="row mt-3"> <div class="col-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/ai_revolution/worldindata-480.webp 480w,/assets/img/blog/ai_revolution/worldindata-800.webp 800w,/assets/img/blog/ai_revolution/worldindata-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/ai_revolution/worldindata.png" class="img-fluid w-100 rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The freelance market, often a bellwether for economic shifts, offered surprising insights. <a href="https://www.upwork.com/research/generative-ai-work-value">Upwork reported a growth in sectors most susceptible to automation</a>. While writing and translation declined, video production surged by 40%, and web/graphic design grew 8-10%. Counter-intuitively, the most “at-risk” occupations are thriving.</p> <p>Why? Because AI isn’t replacing these roles – it’s augmenting them. Professionals can now deliver higher-quality work more efficiently. Generative AI’s text and image output itself lack intrinsic meaning but become valuable when expertly integrated into larger products or services. This efficiency extends across industries, with AI agents like <a href="https://www.cognition.ai/blog/introducing-devin">Devin</a> showing promise in automating complex software engineering tasks.</p> <div style="text-align: center;"> <iframe width="560" height="315" src="https://www.youtube.com/embed/fjHtjT7GO1c?si=k3do5ZkhgX5lzlMO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </div> <p><br/></p> <h2 id="the-augmentation-effect">The Augmentation Effect</h2> <p>This is the key to understanding AI’s true impact: it’s not about replacement, but amplification. A single AI-augmented worker can now accomplish tasks that previously required entire teams. We’ve entered the AI era, economically proven at the industry’s forefront. While precise figures are lacking, the shifts are palpable – gradual integration and nuanced specialisation are consolidating into faster processes and higher productivity.</p> <p>This is why I partly disagree with Acemoglu’s <a href="https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf">recent conservative estimates of AI’s economic impact</a>, but align more with his <a href="https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3">older work on technological change</a>. The real transformation will come from workers dramatically increasing their output and value - imagine £X workers doing £2X work, or even delivering £3X value. These shifts are already happening in the contingent work space, likely foreshadowing broader changes. While AI’s overall economic impact remains debated, I believe we’ll see a dual effect: <strong>initial displacement (of lower-value tasks) as AI automates certain functions, followed by reinstatement as new, higher-value jobs and tasks emerge</strong>.</p> <h2 id="curation-and-domain-expertise">Curation and Domain Expertise</h2> <p>In this new era, success hinges on curation – the ability to effectively integrate AI-generated outputs into cohesive, purpose-driven solutions. This requires not just technical skills, but deep domain understanding: designers must weave aesthetics and cultural insights into compelling visual narratives; developers need to architect complex systems and translate business needs into efficient, scalable solutions.</p> <p>The true differentiator isn’t in merely using AI tools, but in applying fundamental domain expertise to contextualise AI outputs. This underscores a timeless truth: in a world of rapid technological change, a strong foundation in the fundamentals of your field is more crucial than ever.</p> <h2 id="references">References</h2> <ul> <li> <p>📚 <a href="https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf">Situational Awareness</a> by Leopold Aschenbrenner, ex-Superalignment team member at <a href="https://openai.com/">OpenAI</a>. This 165-page manifesto predicts AI’s rapid development until 2027, potentially reaching AGI levels, based on physical compute scaling, algorithmic efficiency, and “unhobbling” of current AI models. This development could lead to AI capable of automating AI research itself, potentially triggering an intelligence explosion and dramatically accelerating scientific and technological progress.</p> </li> <li> <p>🔍 <a href="https://doi.org/10.1002/smj.3286">Occupational, Industry, and Geographic Exposure to Artificial Intelligence</a> by Edward Felton, Manav Raj, and Rob Seamans. Introduces the AI Occupational Exposure (AIOE) dataset, ranking industries and occupations based on their AI vulnerability.</p> </li> <li> <p>📊 <a href="https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf">The Simple Macroeconomics of AI</a> by Daron Acemoglu. Offers a conservative estimate of AI’s impact on productivity, challenging more optimistic projections from Goldman Sachs and McKinsey.</p> </li> <li> <p>🔄 <a href="https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3">Automation and New Tasks: How Technology Displaces and Reinstates Labor</a> by Acemoglu and Restrepo. Presents a framework for understanding how technological changes affect labour demand.</p> </li> <li> <p>💼 <a href="https://www.upwork.com/research/generative-ai-work-value">The Impact of AI on the Job Market: Key Insights</a> by <a href="https://www.upwork.com/">Upwork</a> Research Institute. Reveals generative AI’s asymmetric impact on the freelance market, benefiting high-skill workers while challenging those in low-value tasks.</p> </li> <li> <p>📈 <a href="https://ourworldindata.org/artificial-intelligence">Our World in Data: Artificial Intelligence</a> visualises AI systems’ performance relative to humans across various capabilities.</p> </li> <li> <p>🤖 <a href="https://youtu.be/fjHtjT7GO1c?si=514LxM3jbaS-eQv">Introducing Devin: the first AI software engineer</a> A video demonstrating Devin by <a href="https://www.cognition.ai/">Cognition</a>, an AI agent showing promising capabilities in automating complex software engineering tasks.</p> </li> </ul>]]></content><author><name></name></author><category term="article"/><category term="AI"/><category term="FutureOfWork"/><category term="AIAugmentation"/><category term="WorkforceEvolution"/><summary type="html"><![CDATA[In this piece I discuss, despite media anxiety, frontline industries show AI augmenting rather than replacing jobs, with unexpected growth in "at-risk" sectors.]]></summary></entry></feed>